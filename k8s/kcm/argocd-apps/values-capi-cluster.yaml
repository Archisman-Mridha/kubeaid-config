global:
  clusterName: kcm
  kubernetes:
    version: v1.33.0
  kubeaid:
    repo: https://github.com/Archisman-Mridha/kubeaid
  kubeaidConfig:
    repo: https://github.com/Archisman-Mridha/kubeaid-config
  additionalUsers: 
    - name: archi
      sshPublicKey: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQC6dc7jP7zQT7qSKkFJd4pOMZmTb0kx8R29A3DbzLaDSSepEGtJ+64taQ4YI1C5/l7BFdi8blb1N135tRf54YY1v1plFDzukjxMx8GLa965T4YuSPg/1PhNQfsUcGDL/LXMktJiJP8pYvQKnOjM6KHju1GJKPlmlWHkttyFk6KmkeltF+ljPRGJhpOUjvM9RJgsYqiy6+pb8hGKxQi4dQ07duj7y7N/0pPbHg/BrtpbtHm2r/fsrFfzVwqIRg61LKxrcTZ4HPGpKPoare+X+wbp85hQOfWr6KtG9cQMjGbneZTYAYXhQxYlr2XlbGq/yj9mQJxYg/rEIL/EQY12An4zdI2hqpNlgkZwioc2agCGs3HvtQY64gpSF/M530Wx6Dm2e9eltSj+frr+WJdz3QXqO84dUENllFavL+gSGuT+MBzYOCsCAlKzKEj1EZ4ivkpYaNvTNrVqFpNMPsvuX3nAjlcl3g2Wmkb+hjPjTH84glNEvFsc2FYLSaU46jyb6UJ3aSUaJsCBIQfp4C6BVAYwEe9OzvuJrp8Ky4P5C0t0UvJgfdbUIh5TksTZ5QpyQiMvzpvmhJEWY+BEHHiI2a2ZRs8DPr9NZ0M6aut0AfxdM3YxIRcNU1m8lJc37/QgQETuzKCnQzZwsJF/HdVuXv+VW39kstpvRO/o5ORGaCg/SQ== cardno:13_819_971
provider:
  hetzner: true

hetzner:
  mode: bare-metal
  bareMetal:
    wipeDisks: false
    sshKeyPair:
      name: cluster
    installImage:
      imagePath: /root/.oldroot/nfs/images/Ubuntu-2404-noble-amd64-base.tar.gz
    vg0: 
      size: 25G
      rootVolumeSize: 10G
    diskLayoutSetupCommands: |
      
      set -e
      apt-get update -y
      apt install zfsutils-linux -y
      
      if zpool import -f primary >/dev/null 2>&1; then
        echo "Imported existing primary ZPool"
      else
        # Create the ZPool (in mirror mode) across the NVMe disks.
        zpool create primary mirror /dev/nvme0n1 /dev/nvme1n1
      
        # From that ZPool, set aside 100GB for ContainerD, by creating a ZVolume.
        #
        # A ZFS volume is a dataset that represents a block device. ZFS volumes are identified as
        # devices in the /dev/zvol/{dsk,rdsk}/pool directory.
        zfs create -s -V 100G primary/containerd
        udevadm settle
        mkfs.ext4 /dev/zvol/primary/containerd
      
        # From that ZPool, set aside 50GB for ephemeral volumes for pods, by creating a ZVolume.
        zfs create -s -V 50G primary/pod-ephemeral-volumes
        udevadm settle
        mkfs.ext4 /dev/zvol/primary/pod-ephemeral-volumes
      
        # From that ZPool, set aside 50GB for pod logs, by creating a (thinly provisioned)
        # ZVolume.
        zfs create -s -V 50G primary/pod-logs
        udevadm settle
        mkfs.ext4 /dev/zvol/primary/pod-logs
      fi
      
      mkdir -p /var/lib/containerd
      echo "/dev/zvol/primary/containerd /var/lib/containerd ext4 defaults,nofail 0 0" | tee -a /etc/fstab
      mount /dev/zvol/primary/containerd /var/lib/containerd
      
      mkdir -p /var/lib/kubelet/pods
      echo "/dev/zvol/primary/pod-ephemeral-volumes /var/lib/kubelet/pods ext4 defaults,nofail 0 0" | tee -a /etc/fstab
      mount /dev/zvol/primary/pod-ephemeral-volumes /var/lib/kubelet/pods
      
      mkdir -p /var/log
      echo "/dev/zvol/primary/pod-logs /var/log ext4 defaults,nofail 0 0" | tee -a /etc/fstab
      mount /dev/zvol/primary/pod-logs /var/log
      
      # Enable weekly ZPool trimming for the ZPool.
      # So unused storage space will be reclaimed back, from the ZVolumes into the ZPool.
      # REFER : https://openzfs.github.io/openzfs-docs/man/master/8/zpool-trim.8.html.
      systemctl enable zfs-trim-weekly@rpool.timer --now
      
      # Create partition (without RAID) for Rook Ceph, which will take up the remaining of each HDD.
      echo ",,83" | sfdisk -N 4 /dev/sda --force
      partprobe /dev/sda
      echo ",,83" | sfdisk -N 4 /dev/sdb --force
      partprobe /dev/sdb
      

  controlPlane:
    regions: 
      - fsn1
      - nbg1
      - hel1

    
    bareMetal: 
      endpoint:
        isFailoverIP: true
        host: 65.108.24.157
      bareMetalHosts:
        - serverID: "1866472"
          wwns:
            - "0x50014ee0ae6cabbb"
            - "0x50014ee6b080c608"
        - serverID: "1866482"
          wwns:
            - "0x5000cca25ed86494"
            - "0x5000cca25ecf496b"
        - serverID: "1866484"
          wwns:
            - "0x50014ee2097c6ca4"
            - "0x50014ee2097c9304"
      diskLayoutSetupCommands: ""

    

  nodeGroups: 
    hcloud: []
    bareMetal: []
